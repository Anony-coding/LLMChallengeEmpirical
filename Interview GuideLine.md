

**Purpose:**  
This interview aims to validate and extend our previously constructed taxonomy of LLM-related issues in deep learning (DL) frameworks. We collect insights from two key stakeholder groups—LLM users and DL framework developers—to understand real-world challenges in developing, fine-tuning, deploying, or supporting large language models (LLMs).

**Target Participants:**  
- **LLM Users:** Practitioners who fine-tune, deploy, or experiment with LLMs using DL frameworks.  
- **Framework Developers:** Engineers who build or maintain DL frameworks and support LLM-related functionalities.

**Interview Type:**  
Semi-structured, 30–40 minutes per session, conducted online via video call.

**Structure:**  
Each interview includes four sections:

---

## Part I. Background Information

**Objective:** Understand the participant’s context, experience, and typical tasks.

**Questions:**
1. What is your current role? (e.g., student, researcher, engineer, maintainer)
2. How many years have you worked with LLMs or DL frameworks?
3. Which DL frameworks do you typically use or develop? (e.g., PyTorch, MindSpore, TensorFlow)
4. What types of models do you usually work with?  
   _(e.g., encoder-only, decoder-only, encoder-decode, Multi-Modal; LLMs or smaller models)_
5. What LLM-related tasks do you perform or support?  
   _(Check all that apply: fine-tuning, inference, quantization, model deployment, framework optimization, training pipeline design, bug fixing)_

---

## Part II. Questions and Usability Challenges

**Objective:** Evaluate alignment between the taxonomy and users’ experience with questions or confusion.

### For LLM Users:
- What types of questions or confusion do you commonly encounter when using DL frameworks for LLMs?
- Based on this list of question categories (provided during the interview), please rank the top 3 most frequent or impactful question types.
- Are there any types of questions or usability challenges not covered in our taxonomy?

### For Framework Developers:
- How do users typically raise questions about LLM support in the framework you work on?
- Which types of questions are most difficult to address?
- Do you notice any recurring gaps between framework design and user expectations?

---

## Part III. Bug Reports and Debugging Experience

**Objective:** Validate bug-related themes and understand how users and developers handle critical defects.

### For LLM Users:
- What are the most frustrating bugs you've encountered when working with LLMs in DL frameworks?
- From this list of common bug types, please rank the top 3 in terms of frequency or severity.
- Can you describe a memorable debugging experience involving LLM-related functionality?
- Are there any recurring bugs that are not captured in our taxonomy?

### For Framework Developers:
- What kinds of LLM-related bugs do you most frequently fix?
- How do you prioritize which bugs to resolve?
- What are the most technically challenging or time-consuming bug types to fix?

---

## Part IV. Feature Requirements and Improvement Expectations

**Objective:** Extend requirement-related themes and capture future-facing ideas.

### For LLM Users:
- What LLM-related framework features do you wish were better supported?
- From this list of requirement themes, please rank those most relevant to your work.
- Are there features missing in your current framework that you believe are critical for LLM development?

### For Framework Developers:
- What recent or planned features in your framework target large model support?
- How do you balance between improving LLM-specific features and maintaining general-purpose usability?
- What long-term improvements do you envision for LLM support?

---



